{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzh3OHPIZxa9"
      },
      "source": [
        "# <font color='black'> НИС: регрессионный анализ, 2025 </font>\n",
        "# <font color='black'> О контрольных переменных и переменных-следствиях (коллайдерах) </font>\n",
        "\n",
        "На этом занятии мы продолжим работать с данными из статьи [Kalenborn C., Lessman C., 2013](https://yadi.sk/i/nlEQUoWKiqY0UA). Одна из частей анализа в данной статье выполнена на основе cross-section data (использованы усредненные данные за 2005 - 2010 гг.). Авторы изучают взаимосвязь уровня коррупции и демократии, предполагая, что ее характер зависит от значений показателя свободы прессы. Кратко о данных:\n",
        "* cpi - уровень коррупции: Corruption Perception Index. Непрерывная шкала от 0 до 10, где 10 означает наиболее высокий уровень коррупции.\n",
        "* dem - индекс демократии: Vanhanen’s democratization index. Непрерывная шкала от 0 до 100, где 100 означает максимальное значение уровня демократии.\n",
        "* fp - свобода прессы: Freedom House. Приведен к непрерывной шкале от 0 до 100, где 100 - наиболее высокое значение свободы прессы.\n",
        "* loggdppc - натуральный логарифм ВВП на душу населения. World Bank.\n",
        "* stab - уровень политической стабильности. Индекс построен на основе показателей \"Political Stability\" и \"Absence of Violence/Terrorism\" из the Worldwide Governance Indicators. Непрерывная шкала от -2.5 до 2.5, где 2.5 соответствует наиболее высокому уровню политической стабильности.\n",
        "* britcol - дамми-переменная, где 1 - бывшая британская колония."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlt5pEfkZxbB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "sns.set(style = \"white\", palette='deep')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p5vjuPdZxbF"
      },
      "source": [
        "Откроем массив данных для репликации результатов исследования - lab1.dta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU_dW4geZxbH"
      },
      "outputs": [],
      "source": [
        "lab2 = pd.read_stata('lab1.dta')\n",
        "lab2 = lab2.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxS2DTWZxbN"
      },
      "source": [
        "Оценим для начала регрессионную модель без переменных взаимодействия. Проинтерпретируйте все оценки коэффициентов модели m1. Как изменилась оценка коэффициента при dem по сравнению с соответствующей оценкой в модели m0?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKCqndryZxbO"
      },
      "outputs": [],
      "source": [
        "m1 = smf.ols(formula = \"cpi ~ dem + fp + loggdppc + britcol + stab\", data = lab2).fit(cov_type = \"HC3\")\n",
        "print(m1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Альтернатива: Мы можем получить оценку коэффициента при любом предикторе в такой модели, воспользуясь теоремой Фриша-Во-Ловелла (the Frisch-Waugh-Lovell theorem). К примеру, для того, чтобы получить оценку коэффициента при переменной dem, а именно, оценить, как связаны dem и cpi, нужно очистить вариацию этих переменных от других предикторов (а именно, от fp, loggdppc, britcol и stab, с другой).\n",
        "\n",
        "1) Для этого мы оцениваем регрессию dem на fp, loggdppc, britcol и stab, сохраняем остатки - то есть, получаем очищенный показатель dem.\n",
        "\n",
        "2) Далее аналогично оцениваем регрессию cpi на fp, loggdppc, britcol и stab, сохраняем остатки - то есть, получаем очищенный показатель cpi.\n",
        "\n",
        "3) После этого достаточно будет оценить регрессию очищенного cpi на очищенный dem и убедиться, что мы получили тот же самый коэффициент при dem, что и в исходной модели с контрольными переменными."
      ],
      "metadata": {
        "id": "AHWHKVsCmKkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1_1 = smf.ols(formula = \"dem ~ fp + loggdppc + britcol + stab\", data = lab2).fit()\n",
        "resid_data = pd.DataFrame()\n",
        "resid_data[\"res1\"] = m1_1.resid"
      ],
      "metadata": {
        "id": "ED0RVLhfosTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1_2 = smf.ols(formula = \"cpi ~ fp + loggdppc + britcol + stab\", data = lab2).fit()\n",
        "resid_data[\"res2\"] = m1_2.resid"
      ],
      "metadata": {
        "id": "rEAubYnQpEuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1_3 = smf.ols(formula = \"res2 ~ res1\", data = resid_data).fit(cov_type = \"HC3\")\n",
        "print(m1_3.summary())"
      ],
      "metadata": {
        "id": "OgWaAzmlpPV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для того, чтобы лучше понять, что скрывается за процессом очищения вариации, представим себе следующее. Мы включаем в модель категориальную контрольную переменную. Далее реализуем следующие шаги:\n",
        "\n",
        "1) разделим исходный массив на подгруппы в зависимости от количества категорий в контрольной переменной\n",
        "\n",
        "2) оценим регрессионную модель $y$ на $x$ для каждого подмассива, итого получим J оценок коэффициентов наклона при $x$, где J - это количество категорий контрольной переменной   \n",
        "\n",
        "3) взвесим результаты: суммируем взвешенные оценки коэффициентов, в качестве веса будет выступать доля подвыборки в общем массиве $∑w_j\\hat{\\beta}_j$\n",
        "\n",
        "Таким образом, очищение вариации равносильно тому, как если бы мы исследовали взаимосвязь $x$ и $y$ при фиксированном значении контрольной переменной"
      ],
      "metadata": {
        "id": "2owdgZFzQtJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим для иллюстрации исходную модель. При этом сфокусируемся на разделении выборки по бинарной контрольной переменной britcol\n",
        "\n",
        "Итак, всего у нас 170 наблюдений"
      ],
      "metadata": {
        "id": "PyvngSRjdTgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(lab2)"
      ],
      "metadata": {
        "id": "rYKXWvOidYkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из них 38 стран - бывшие британские колонии, оставшиеся 132 страны - страны, которые не являются бывшими британскими колониями"
      ],
      "metadata": {
        "id": "K4skfh2GdgwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Страны, которые не являются бывшими британскими колониями: {len(lab2[lab2['britcol'] == 0])} стран\")\n",
        "print(f\"Бывшие британские колонии: {len(lab2[lab2['britcol'] == 1])} стран\")"
      ],
      "metadata": {
        "id": "PftRTUsndslA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим регрессионную модель на соответствующих подвыборках:"
      ],
      "metadata": {
        "id": "x5TX9HN6e_5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_group0 = smf.ols(formula='cpi ~ dem + fp + loggdppc + stab',\n",
        "                      data=lab2[lab2['britcol'] == 0]).fit()\n",
        "\n",
        "print(m_group0.summary())"
      ],
      "metadata": {
        "id": "Jrbb0KvzfGqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_group1 = smf.ols(formula='cpi ~ dem + fp + loggdppc + stab',\n",
        "                      data=lab2[lab2['britcol'] == 1]).fit()\n",
        "\n",
        "print(m_group1.summary())"
      ],
      "metadata": {
        "id": "Y0GOxic1fPYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним результаты в полной модели с учетом контрольной переменной britcol и с учетом деления на подвыборки:"
      ],
      "metadata": {
        "id": "6F2MhQK8fsvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = ['dem', 'fp', 'loggdppc', 'stab']\n",
        "comparison = []\n",
        "\n",
        "for x in X:\n",
        "        comparison.append({\n",
        "            'variable': x,\n",
        "            'group0': m_group0.params[x],\n",
        "            'group1': m_group1.params[x],\n",
        "            'total': m1.params[x],\n",
        "            'weight_group0': len(lab2[lab2['britcol'] == 0]) / len(lab2),\n",
        "            'weight_group1': len(lab2[lab2['britcol'] == 1]) / len(lab2)\n",
        "        })\n",
        "\n",
        "comparison = pd.DataFrame(comparison)\n",
        "\n",
        "comparison"
      ],
      "metadata": {
        "id": "6pQ2aV-Kf0t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Взвесим результаты на долю наблюдений."
      ],
      "metadata": {
        "id": "Kkh1t180iAb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison['weighted_coef'] = comparison['group0']*comparison['weight_group0'] + comparison['group1']*comparison['weight_group1']\n",
        "\n",
        "comparison"
      ],
      "metadata": {
        "id": "Myj28D0CiI3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полученные результаты взвешивания показывают близкие результаты к исходным результатам оценивания модели на всей выборке."
      ],
      "metadata": {
        "id": "kLhHpngGkb9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Несколько сложнее обстоят дела с непрерывной контрольной переменной. Размер подвыборки, с одной стороны, должен быть не слишком маленьким для оценивания регрессионной модели с заданным количеством параметров. С другой стороны, создавать слишком большие подвыборки также нецелесообразно, так как можно упустить различия во взаимосвязи, проявляющиеся в разных подмассивах, и в результате получить плохое приближение к оценкам модели по всей выборке. В связи с этим поделим массив на подвыборки из расчета, чтобы в подвыборке было хотя бы 30 наблюдений (с учетом нагруженности спецификации модели следует корректировать размер подвыборки):     "
      ],
      "metadata": {
        "id": "JhYY6fLqnK_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab2['stab_quartile'] = pd.qcut(lab2['stab'], q=4, labels=False)\n",
        "\n",
        "X = ['dem', 'fp', 'loggdppc', 'britcol']\n",
        "comparison = []\n",
        "\n",
        "for x in X:\n",
        "    coefs_by_quartile = []\n",
        "    weights_by_quartile = []\n",
        "\n",
        "    for quartile in sorted(lab2['stab_quartile'].unique()):\n",
        "        quartile_data = lab2[lab2['stab_quartile'] == quartile]\n",
        "\n",
        "        if len(quartile_data) > 30:\n",
        "            model = smf.ols('cpi ~ dem + fp + loggdppc + britcol', data=quartile_data).fit()\n",
        "            coefs_by_quartile.append(model.params[x])\n",
        "            weights_by_quartile.append(len(quartile_data) / len(lab2))\n",
        "\n",
        "    weighted_coef = np.average(coefs_by_quartile, weights=weights_by_quartile)\n",
        "\n",
        "    comparison.append({\n",
        "        'variable': x,\n",
        "        'total': m1.params[x],\n",
        "        'weighted_coef': weighted_coef\n",
        "    })\n",
        "\n",
        "comparison = pd.DataFrame(comparison)\n",
        "comparison"
      ],
      "metadata": {
        "id": "p-eag1l2poXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При этом переменные-\"общие следствия\" (collider variables) являются вредными контрольными переменными. В исходных данных мы можем наблюдать отсутствие связи либо слабую связь. Однако при включении переменной-коллайдера может возникнуть ложная связь: к примеру, $P(Y=1 | X=1 ∩ C=1) ≠ P(Y=1 | X=0 ∩ C=1)$. То есть, при фиксированном значении коллайдера возникает связь, которой изначально могло и не быть в исходном массиве\n",
        "\n",
        "Сгенерим данные для того, чтобы проиллюстрировать смещение в оценках коэффициентов в результате включения неподходящей контрольной переменной:"
      ],
      "metadata": {
        "id": "oC8pGusPNO6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "dem_r = norm.rvs(5, 1.5, 1000)\n",
        "\n",
        "cpi_r = 10 - 1.2*dem_r + norm.rvs(0, 1, 1000)\n",
        "\n",
        "educ_r = 5 + 0.8*dem_r - 0.7 * cpi_r + norm.rvs(0, 0.5, 1000)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'cpi_r': cpi_r,\n",
        "    'dem_r': dem_r,\n",
        "    'educ_r': educ_r\n",
        "})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_Um-88G84Q3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['dem_r'].corr(df['cpi_r']), 3)"
      ],
      "metadata": {
        "id": "kN8c1Qaq4lU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "scatter = sns.regplot(data=df, x=\"dem_r\", y=\"cpi_r\")\n",
        "\n",
        "plt.title(\"Взаимосвязь индексов демократии и коррупции\",\n",
        "          fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Индекс демократии\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"Индекс восприятия коррупции\", fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvLDd1M-4-jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_r1 = smf.ols('cpi_r ~ dem_r', data=df).fit(cov_type = \"HC3\")\n",
        "print(m_r1.summary())\n"
      ],
      "metadata": {
        "id": "o8IqRgcd5TbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m_educ_r = smf.ols('cpi_r ~ dem_r + educ_r', data=df).fit(cov_type = \"HC3\")\n",
        "\n",
        "print(m_educ_r.summary())"
      ],
      "metadata": {
        "id": "n9wM-Sc05gUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['educ_levels'] = pd.qcut(df['educ_r'], q=30, labels=False)\n",
        "\n",
        "X = ['dem_r']\n",
        "comparison = []\n",
        "\n",
        "for x in X:\n",
        "    coefs_by_quartile = []\n",
        "    weights_by_quartile = []\n",
        "\n",
        "    for quartile in sorted(df['educ_levels'].unique()):\n",
        "        quartile_data = df[df['educ_levels'] == quartile]\n",
        "\n",
        "        if len(quartile_data) > 30:\n",
        "            model = smf.ols('cpi_r ~ dem_r', data=quartile_data).fit()\n",
        "            coefs_by_quartile.append(model.params[x])\n",
        "            weights_by_quartile.append(len(quartile_data) / len(df))\n",
        "\n",
        "    weighted_coef = np.average(coefs_by_quartile, weights=weights_by_quartile)\n",
        "\n",
        "    comparison.append({\n",
        "        'variable': x,\n",
        "        'total': m_r1.params[x],\n",
        "        'weighted_coef': weighted_coef\n",
        "    })\n",
        "\n",
        "comparison = pd.DataFrame(comparison)\n",
        "comparison"
      ],
      "metadata": {
        "id": "kZvuP0Rj6WlZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}