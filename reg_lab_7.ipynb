{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='black'>НИС: регрессионный анализ, 2025 </font>\n",
        "## <font color='black'> Практическое занятие: Гребневая регрессия. Меры качества регрессионной модели. Сравнение альтернативных спецификаций моделей </font>\n",
        "\n",
        "В рамках данного практического занятия мы рассмотрим реализацию метода гребневой регрессии. Исходные данные:\n",
        "\n",
        "* lngdp2 - логарифм ВВП на душу населения - зависимая переменная\n",
        "\n",
        "В качестве предикторов выступают 6 индексов качества гос. управления WGI (Worldwide Governance Indicators)\n",
        "* va - voice and accountability\n",
        "* rl - rule and law\n",
        "* rq - regulatory quality\n",
        "* gove - government effectiveness\n",
        "* ps - political stability\n",
        "* cc - control of corruption\n",
        "\n",
        "Распределения этих индексов приведено в рамках проекта к стандартному нормальному, поэтому мы не используем дополнительно стандартизацию"
      ],
      "metadata": {
        "id": "H_Hl_bxeq9QV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa5l7-vwbmg5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.stats.anova import anova_lm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dta = pd.read_stata('data_ridge.dta')\n",
        "dta = dta.dropna()"
      ],
      "metadata": {
        "id": "WPi8_Vv6b_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим модель m1 на исходных данных. Можем ли мы доверять полученным результатам?"
      ],
      "metadata": {
        "id": "VnohXT-tocIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = smf.ols(formula = \"lngdp2 ~ va + rl + rq + gove + ps + cc\", data = dta).fit()\n",
        "print(m1.summary())"
      ],
      "metadata": {
        "id": "vjvGbsQ1cNBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем корреляционную матрицу для наших предикторов:"
      ],
      "metadata": {
        "id": "2cRtovm3omKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dta[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]].corr().round(3)"
      ],
      "metadata": {
        "id": "xDAgKsxUEAmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кроме этого, понять, есть ли у нас свидетельства в пользу сильной мультиколлинеарности, нам помогут коэффициенты VIF (коэффициенты \"вздутия\" дисперсии). Проинтерпретируйте полученные результаты"
      ],
      "metadata": {
        "id": "5jopGWkposmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dta[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]]\n",
        "X = add_constant(X)\n",
        "\n",
        "vif_data = pd.DataFrame({'variables':X.columns[1:], 'VIF':[variance_inflation_factor(X.values, i+1) for i in range(len(X.columns[1:]))]})\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "hgy-poo_cQB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Применим гребневую регрессию для получения более устойчивых результатов. Воспользуемся процедурой кросс-валидации для подбора оптимального параметра регуляризации. Разделим наш массив на 2 подвыборки: тестовую (20% данных) и обучающую (соответственно, 80% данных)"
      ],
      "metadata": {
        "id": "pLSk46fTO-hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(dta, test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "FQQMN5eQciW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала используем 1 в качестве параметра регуляризации и выведем оценки коэффициентов в модели гребневой регрессии:"
      ],
      "metadata": {
        "id": "3s6Rqn4rRtyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge1 = Ridge(alpha = 1)\n",
        "ridge1.fit(train[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]], train[\"lngdp2\"])\n",
        "ridge1.coef_"
      ],
      "metadata": {
        "id": "BJLFJJsvc1Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функцию для расчета стандартных ошибок:"
      ],
      "metadata": {
        "id": "oZM8moeFpTji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ridge_se(model, X, y):\n",
        "    n, p = X.shape\n",
        "    X_matrix = X.values if hasattr(X, 'values') else X\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "    residuals = y - y_pred\n",
        "    sigma_sq = np.sum(residuals**2) / (n - p - 1)\n",
        "\n",
        "    XTX = X_matrix.T @ X_matrix\n",
        "    lambda_I = model.alpha * np.eye(p)\n",
        "    inv_matrix = np.linalg.inv(XTX + lambda_I)\n",
        "\n",
        "    cov_matrix = sigma_sq * inv_matrix @ XTX @ inv_matrix\n",
        "    se = np.sqrt(np.diag(cov_matrix))\n",
        "\n",
        "    return se"
      ],
      "metadata": {
        "id": "5DxLEL49R29M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассчитаем стандартные ошибки для оценок коэффициентов нашей первой модели гребневой регрессии:"
      ],
      "metadata": {
        "id": "PIE3c4SopaeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]]\n",
        "y = train['lngdp2']\n",
        "se1 = ridge_se(ridge1, X, y)\n",
        "\n",
        "se1"
      ],
      "metadata": {
        "id": "f8qC0lWNSroy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства представим ниже таблицу, в которой сравним оценки коэффициентов и их значимость в исходной модели и модели гребневой регрессии (с параметром $\\alpha$ = 1):"
      ],
      "metadata": {
        "id": "lDl3q--IphUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge1_data = pd.DataFrame({'variables':X.columns, 'coef': m1.params[1:], 'se': m1.bse[1:], 't': m1.params[1:]/m1.bse[1:],\n",
        "                            'coef_ridge':ridge1.coef_, 'se_ridge': se1, 't_ridge': ridge1.coef_/se1})\n",
        "print(ridge1_data)"
      ],
      "metadata": {
        "id": "13rjk4sJVFRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подберем оптимальный параметр регуляризации. Для этого используем k-блочную кросс-валидацию: то есть, массив разбивается на k равных подвыборок, далее проводим для каждого заданного параметра $\\alpha$ k итераций: j-ая подвыборка выступает тестовой, остальные подвыборки составляют обучающую. Считаем среднее MSE по k итерациям для каждого значения $\\alpha$ и далее останавливаемся на том значении $\\alpha$, при котором усредненное MSE принимает минимальное значение"
      ],
      "metadata": {
        "id": "q3TJNUD6jMTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "grid_search = GridSearchCV(ridge1, {'alpha': alphas}, cv = 5)\n",
        "grid_search.fit(train[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]], train[\"lngdp2\"])\n",
        "\n",
        "print(\"Best Regularization Parameter:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "xq-nOoY4d2gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge2 = Ridge(alpha = 10)\n",
        "ridge2.fit(train[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]], train[\"lngdp2\"])\n",
        "ridge2.coef_"
      ],
      "metadata": {
        "id": "vgHrBWeTegj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "se2 = ridge_se(ridge2, X, y)\n",
        "\n",
        "se2"
      ],
      "metadata": {
        "id": "hr4VUcfHX5vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge2_data = pd.DataFrame({'variables':X.columns, 'coef': m1.params[1:], 'se': m1.bse[1:], 't': m1.params[1:]/m1.bse[1:],\n",
        "                            'coef_ridge':ridge2.coef_, 'se_ridge': se2, 't_ridge': ridge2.coef_/se2})\n",
        "print(ridge2_data)"
      ],
      "metadata": {
        "id": "LXutCvWDYB2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее для понимания, можем ли мы обобщать результаты на более широкую выборку, сравним $R^2$ и $MSE$ на тестовой и обучающей подвыборках:"
      ],
      "metadata": {
        "id": "wYNXZxGQp2ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = ridge2.predict(test[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]])\n",
        "mse_test = mean_squared_error(test[\"lngdp2\"], y_pred_test)"
      ],
      "metadata": {
        "id": "VK5m6XjsenuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_test = r2_score(test[\"lngdp2\"], y_pred_test)"
      ],
      "metadata": {
        "id": "a_nTjbDRev5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = ridge2.predict(train[[\"va\", \"rl\", \"rq\", \"gove\", \"ps\", \"cc\"]])\n",
        "mse_train = mean_squared_error(train[\"lngdp2\"], y_pred_train)"
      ],
      "metadata": {
        "id": "RQ5ijUPXfOex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_train = r2_score(train[\"lngdp2\"], y_pred_train)"
      ],
      "metadata": {
        "id": "WR4hNCzSfVrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'R2 обучающая выборка: {r2_train:.3f}\\nR2 тестовая выборка: {r2_test:.3f}')\n",
        "print(f'MSE обучающая выборка: {mse_train:.3f}\\nMSE тестовая выборка: {mse_test:.3f}')"
      ],
      "metadata": {
        "id": "KUgudE6WfuJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим две спецификации модели, вложенные друг в друга - они будут различаться на один параметр. Проследим, как изменяются меры коэффициента детерминации и скорректированного коэффициента детерминации с добавлением предиктора.\n",
        "\n",
        "$R^2$ скорректированный ($R^2_{adj}$) штрафует модель за \"нагруженность\", то есть, за дополнительные предикторы. $R^2_{adj}$ рассчитывается по следующей формуле:\n",
        "\n",
        "$R^2_{adj} = 1 - \\frac{RSS \\times (N-1)}{TSS \\times (N-k-1)}$, где k - это количество предикторов в модели"
      ],
      "metadata": {
        "id": "_w_chwVo3Fwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = smf.ols(formula = \"lngdp2 ~ rl\", data = dta).fit(cov_type = \"HC3\")\n",
        "print(m2.summary())"
      ],
      "metadata": {
        "id": "2PUgM0Ko3S-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3 = smf.ols(formula = \"lngdp2 ~ rl + va\", data = dta).fit(cov_type = \"HC3\")\n",
        "print(m3.summary())"
      ],
      "metadata": {
        "id": "PZhfblP03_t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model2 R-squared:\", m2.rsquared.round(3), \"Model2 R-squared adjusted:\", m2.rsquared_adj.round(3))\n",
        "print(\"Model3 R-squared:\", m3.rsquared.round(3), \"Model3 R-squared adjusted:\", m3.rsquared_adj.round(3))"
      ],
      "metadata": {
        "id": "vGYe7hgA5N9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В то время как $R^2$ увеличивается с добавлением новых предикторов, $R^2_{adj}$ может и уменьшиться (в случае добавленных незначимых предикторов). Для лучшего понимания выведем отдельно таблицу разложения вариации для m3."
      ],
      "metadata": {
        "id": "fyK7V14g51Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(anova_lm(m3))"
      ],
      "metadata": {
        "id": "Ag1X30Me58AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Важно понять, устойчивы ли показатели качества регрессионной модели. Для того, чтобы результаты были более обоснованы и не опирались лишь на одно разбиение массива на тестовую и обучающую выборки, используем k-блочную кросс-валидацию (поделим данные на 5 фолдов, проведем 5 итераций и усредним полученные результаты: на каждой итерации алгоритма модель обучается на 4 фолдах, тестируется на оставшейся 5-ой части выборки).\n",
        "\n",
        "Как мы видим, результаты неустойчивы, что вполне объяснимо с учетом наших данных и спецификации модели"
      ],
      "metadata": {
        "id": "o8ZlyXqScJsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dta[[\"rl\", \"va\"]]\n",
        "y = dta[\"lngdp2\"]"
      ],
      "metadata": {
        "id": "DAEJIXUSepBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "R2 = []"
      ],
      "metadata": {
        "id": "Lre1dni1e2R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    m1.cv = LinearRegression()\n",
        "    m1.cv.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = m1.cv.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    R2.append(r2)\n",
        "\n",
        "    print(\"Fold\", fold+1, \"R2:\", r2)\n",
        "\n",
        "average_R2 = sum(R2) / len(R2)\n",
        "print(\"Average R2:\", average_R2)"
      ],
      "metadata": {
        "id": "oEzy2JBTfTcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним альтернативные спецификации моделей m3 и m4 при помощи информационных критериев AIC и BIC."
      ],
      "metadata": {
        "id": "DnT3wR5VrgxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m4 = smf.ols(formula = \"lngdp2 ~ va + ps\", data = dta).fit(cov_type = \"HC3\")\n",
        "print(m4.summary())"
      ],
      "metadata": {
        "id": "czIelFN3rssN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aic_m3 = m3.aic\n",
        "aic_m4 = m4.aic\n",
        "\n",
        "bic_m3 = m3.bic\n",
        "bic_m4 = m4.bic\n",
        "\n",
        "print(\"Model3 AIC:\", aic_m3.round(3), \"Model4 AIC:\", aic_m4.round(3))\n",
        "print(\"Model3 BIC:\", bic_m3.round(3), \"Model4 BIC:\", bic_m4.round(3))"
      ],
      "metadata": {
        "id": "ys7tbGKMsPok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = len(m3.params)\n",
        "LL = m3.llf\n",
        "aicm3 = 2*p - 2*LL\n",
        "aicm3"
      ],
      "metadata": {
        "id": "QqOmXP1DssHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bicm3 = np.log(len(dta))*p - 2*LL\n",
        "bicm3"
      ],
      "metadata": {
        "id": "saib6FBqs7KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для вложенных моделей мы можем использовать F-test. Статистика для этого теста рассчитывается следующим образом:\n",
        "\n",
        "$F = \\frac{(RSS_{short} - RSS_{long})/Δ df}{RSS_{long}/df_{long}}$\n",
        "\n",
        "При верной нулевой гипотезе такая статистика имеет распределение Фишера с количеством степеней свободы: $df_{1} = \\Delta df$, $df_{2} = df_{long}$"
      ],
      "metadata": {
        "id": "2VPJ51I2tgwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anovaResults = anova_lm(m2, m3)\n",
        "print(anovaResults)"
      ],
      "metadata": {
        "id": "Py60Cz7stnSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}